{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Hybrid Search with HybridRetriever\n",
    "\n",
    "In the previous notebooks, you used **vector search** (semantic similarity) and **full-text search** (keyword matching) separately. Each has strengths:\n",
    "\n",
    "- **Vector search** finds content by meaning — \"thermal management\" matches \"cooling system\"\n",
    "- **Full-text search** finds exact terms — \"HVB_3900\" matches only that specific ID\n",
    "\n",
    "The `HybridRetriever` from neo4j-graphrag **combines both approaches** in a single query, giving you the best of both worlds. It merges results from a vector index and a full-text index, using a configurable **alpha** parameter to balance between them.\n",
    "\n",
    "**Prerequisites:** Complete [02 Embeddings](02_embeddings.ipynb) and [05 Full-Text Search](05_fulltext_search.ipynb) first.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Use `HybridRetriever` to combine vector and full-text search\n",
    "- Tune the `alpha` parameter to balance semantic vs. keyword matching\n",
    "- Use `HybridCypherRetriever` for graph-enhanced hybrid search\n",
    "- Build a complete GraphRAG pipeline with hybrid retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "First, install the required packages. This only needs to be run once per session."
   ]
  },
  {
   "cell_type": "code",
   "id": "install-deps",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install neo4j-graphrag with Bedrock support\n",
    "%pip install \"neo4j-graphrag[bedrock] @ git+https://github.com/neo4j-partners/neo4j-graphrag-python.git@bedrock-embeddings\" python-dotenv pydantic-settings nest-asyncio -q"
   ]
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from neo4j_graphrag.retrievers import HybridRetriever, HybridCypherRetriever\n",
    "from neo4j_graphrag.generation import GraphRAG\n",
    "\n",
    "from data_utils import Neo4jConnection, get_llm, get_embedder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connect-header",
   "metadata": {},
   "source": [
    "## Connect to Neo4j\n",
    "\n",
    "Create and verify the connection to your Neo4j graph database."
   ]
  },
  {
   "cell_type": "code",
   "id": "connect",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo4j = Neo4jConnection().verify()\n",
    "driver = neo4j.driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": [
    "## Initialize LLM and Embedder\n",
    "\n",
    "Set up the LLM and embedding model from AWS Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "id": "llm-setup",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "llm = get_llm()\n",
    "embedder = get_embedder()\n",
    "\n",
    "print(f\"LLM: {llm.model_id}\")\n",
    "print(f\"Embedder: {embedder.model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hybrid-intro",
   "metadata": {},
   "source": [
    "## How Hybrid Search Works\n",
    "\n",
    "The `HybridRetriever` runs **two searches in parallel**:\n",
    "\n",
    "1. **Vector search** on the `requirement_embeddings` index — finds semantically similar chunks\n",
    "2. **Full-text search** on the `requirement_text` index — finds keyword-matching chunks\n",
    "\n",
    "It then **merges and ranks** the results. The `alpha` parameter controls the balance:\n",
    "\n",
    "```\n",
    "alpha = 1.0  →  100% vector search (pure semantic)\n",
    "alpha = 0.5  →  50/50 blend (balanced)\n",
    "alpha = 0.0  →  100% full-text search (pure keyword)\n",
    "```\n",
    "\n",
    "This lets you tune retrieval for your use case. For manufacturing requirements, a balanced approach often works best — semantic understanding captures conceptual queries while keyword matching catches specific IDs and standards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retriever-header",
   "metadata": {},
   "source": [
    "## Initialize HybridRetriever\n",
    "\n",
    "Create a `HybridRetriever` that combines both search approaches."
   ]
  },
  {
   "cell_type": "code",
   "id": "hybrid-retriever",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "hybrid_retriever = HybridRetriever(\n",
    "    driver=driver,\n",
    "    vector_index_name='requirement_embeddings',\n",
    "    fulltext_index_name='requirement_text',\n",
    "    embedder=embedder,\n",
    "    return_properties=['text']\n",
    ")\n",
    "\n",
    "print(\"HybridRetriever initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-search-header",
   "metadata": {},
   "source": [
    "## Basic Hybrid Search\n",
    "\n",
    "Let's start with a basic hybrid search to see the combined results."
   ]
  },
  {
   "cell_type": "code",
   "id": "basic-search",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Basic hybrid search\n",
    "query = \"What are the thermal management requirements for the battery?\"\n",
    "result = hybrid_retriever.search(query_text=query, top_k=5)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\")\n",
    "print(f\"Results: {len(result.items)}\\n\")\n",
    "\n",
    "for i, item in enumerate(result.items):\n",
    "    score = item.metadata.get('score', 'N/A')\n",
    "    content_preview = str(item.content)[:120]\n",
    "    print(f\"[{i+1}] Score: {score:.4f} | {content_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-header",
   "metadata": {},
   "source": [
    "## Alpha Tuning\n",
    "\n",
    "The `alpha` parameter is the key to tuning hybrid search. Let's compare different alpha values on the same query to see how the balance affects results.\n",
    "\n",
    "- **High alpha (0.9)**: Emphasizes vector/semantic search — better for conceptual queries\n",
    "- **Balanced alpha (0.5)**: Equal weight — good default for mixed queries\n",
    "- **Low alpha (0.1)**: Emphasizes full-text/keyword search — better for specific terms"
   ]
  },
  {
   "cell_type": "code",
   "id": "alpha-tuning",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compare different alpha values\n",
    "query = \"battery coolant specifications\"\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "\n",
    "for alpha in [0.0, 0.5, 1.0]:\n",
    "    label = {0.0: \"Full-text only\", 0.5: \"Balanced\", 1.0: \"Vector only\"}[alpha]\n",
    "    print(f\"\\n--- Alpha: {alpha} ({label}) ---\")\n",
    "    \n",
    "    result = hybrid_retriever.search(\n",
    "        query_text=query,\n",
    "        top_k=3,\n",
    "    )\n",
    "    \n",
    "    for i, item in enumerate(result.items):\n",
    "        score = item.metadata.get('score', 'N/A')\n",
    "        content_preview = str(item.content)[:100]\n",
    "        print(f\"  [{i+1}] Score: {score:.4f} | {content_preview}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cypher-header",
   "metadata": {},
   "source": [
    "## HybridCypherRetriever: Adding Graph Context\n",
    "\n",
    "Just like `VectorCypherRetriever` adds graph traversal to vector search, `HybridCypherRetriever` adds graph traversal to hybrid search. This gives you the **triple benefit**:\n",
    "\n",
    "1. **Semantic matching** from vector search\n",
    "2. **Keyword matching** from full-text search\n",
    "3. **Graph context** from Cypher traversal\n",
    "\n",
    "The retrieval query uses the same `node` variable pattern as VectorCypherRetriever."
   ]
  },
  {
   "cell_type": "code",
   "id": "hybrid-cypher",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Custom Cypher query for graph-enhanced hybrid retrieval\n",
    "context_query = \"\"\"\n",
    "MATCH (node)<-[:HAS_CHUNK]-(req:Requirement)\n",
    "OPTIONAL MATCH (comp:Component)-[:COMPONENT_HAS_REQ]->(req)\n",
    "OPTIONAL MATCH (prev:Chunk)-[:NEXT_CHUNK]->(node)\n",
    "OPTIONAL MATCH (node)-[:NEXT_CHUNK]->(next:Chunk)\n",
    "WITH node, req, comp, prev, next\n",
    "RETURN \n",
    "    'Component: ' + COALESCE(comp.name, 'N/A') + ' (' + COALESCE(comp.description, '') + ')' +\n",
    "    '\\nRequirement: ' + COALESCE(req.name, 'N/A') +\n",
    "    '\\nContent: ' + COALESCE(prev.text + ' ', '') + node.text + COALESCE(' ' + next.text, '') \n",
    "    AS context,\n",
    "    req.name AS requirement_name\n",
    "\"\"\"\n",
    "\n",
    "hybrid_cypher_retriever = HybridCypherRetriever(\n",
    "    driver=driver,\n",
    "    vector_index_name='requirement_embeddings',\n",
    "    fulltext_index_name='requirement_text',\n",
    "    embedder=embedder,\n",
    "    retrieval_query=context_query\n",
    ")\n",
    "\n",
    "print(\"HybridCypherRetriever initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "hybrid-cypher-search",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test hybrid cypher retrieval\n",
    "query = \"What safety standards must the battery system comply with?\"\n",
    "\n",
    "result = hybrid_cypher_retriever.search(query_text=query, top_k=3)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\")\n",
    "print(f\"Results: {len(result.items)}\\n\")\n",
    "\n",
    "for i, item in enumerate(result.items):\n",
    "    print(f\"[Result {i+1}]\")\n",
    "    print(item.content)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphrag-header",
   "metadata": {},
   "source": [
    "## Complete GraphRAG Pipeline with Hybrid Search\n",
    "\n",
    "Now let's build a complete question-answering pipeline using hybrid search. This combines:\n",
    "- Hybrid retrieval (vector + full-text + graph traversal)\n",
    "- LLM generation for natural language answers\n",
    "\n",
    "This is the most powerful retrieval configuration available — it handles both conceptual questions and specific term lookups, with rich manufacturing context from graph traversal."
   ]
  },
  {
   "cell_type": "code",
   "id": "graphrag-pipeline",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Build complete GraphRAG pipeline with hybrid retrieval\n",
    "rag = GraphRAG(llm=llm, retriever=hybrid_cypher_retriever)\n",
    "\n",
    "query = \"What are the cooling system specifications for the high-voltage battery?\"\n",
    "response = rag.search(query, retriever_config={\"top_k\": 3}, return_context=True)\n",
    "\n",
    "print(f\"Query: \\\"{query}\\\"\\n\")\n",
    "print(\"Answer:\")\n",
    "print(response.answer)"
   ]
  },
  {
   "cell_type": "code",
   "id": "view-context",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# View the retrieved context used by the LLM\n",
    "print(\"Retrieved Context:\")\n",
    "print(\"=\" * 60)\n",
    "for i, item in enumerate(response.retriever_result.items):\n",
    "    print(f\"\\n[Result {i+1}]\")\n",
    "    print(item.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experiment-header",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Experiment with queries that benefit from hybrid search. Notice how some queries are more conceptual (benefit from vector) while others contain specific terms (benefit from full-text)."
   ]
  },
  {
   "cell_type": "code",
   "id": "experiment",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"What are the energy density specifications for battery cells?\",\n",
    "    \"How is the battery pack protected against water ingress?\",\n",
    "    \"What BMS safety monitoring is required?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 60)\n",
    "    response = rag.search(query, retriever_config={\"top_k\": 3})\n",
    "    print(f\"Answer: {response.answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, you built the most comprehensive retrieval system in the workshop:\n",
    "\n",
    "1. **HybridRetriever** — Combines vector search (semantic) with full-text search (keyword) in a single query. The `alpha` parameter lets you tune the balance.\n",
    "\n",
    "2. **HybridCypherRetriever** — Adds graph traversal on top of hybrid search, enriching results with component names, requirement metadata, and adjacent chunks from the manufacturing traceability graph.\n",
    "\n",
    "3. **Alpha tuning** — Higher alpha emphasizes semantic matching (good for conceptual queries); lower alpha emphasizes keyword matching (good for specific terms and IDs).\n",
    "\n",
    "4. **Complete GraphRAG pipeline** — Hybrid retrieval + LLM generation gives the best question-answering performance by leveraging all three dimensions: semantic similarity, keyword relevance, and graph structure.\n",
    "\n",
    "### Retriever Selection Guide\n",
    "\n",
    "| Retriever | When to Use |\n",
    "|-----------|-------------|\n",
    "| `VectorRetriever` | Simple semantic search |\n",
    "| `VectorCypherRetriever` | Semantic search + graph context |\n",
    "| `HybridRetriever` | Semantic + keyword search |\n",
    "| `HybridCypherRetriever` | Semantic + keyword + graph context (most powerful) |\n",
    "\n",
    "---\n",
    "\n",
    "**Congratulations!** You've completed the GraphRAG labs. You now know how to:\n",
    "- Load structured manufacturing data into Neo4j as a traceability graph\n",
    "- Create vector embeddings and full-text indexes on requirement descriptions\n",
    "- Build GraphRAG pipelines with Vector, VectorCypher, and Hybrid retrievers\n",
    "- Enhance retrieval with custom Cypher queries that traverse the manufacturing traceability chain\n",
    "\n",
    "Continue to [Lab 6 - Neo4j MCP Agent](../Lab_6_Neo4j_MCP_Agent/README.md) to learn how to build agents that query the knowledge graph using the Model Context Protocol."
   ]
  },
  {
   "cell_type": "code",
   "id": "cleanup",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "neo4j.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}