{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": "# Data Loading Fundamentals\n\nThis notebook introduces the core concepts of loading structured manufacturing data into Neo4j for GraphRAG applications. You'll learn how to build a manufacturing traceability graph and create text chunks from requirement descriptions for semantic search.\n\n**Learning Objectives:**\n- Understand the manufacturing traceability graph structure\n- Connect to Neo4j from a Jupyter notebook\n- Create Product, TechnologyDomain, and Component nodes using Cypher\n- Create relationships between nodes to form the traceability chain\n- Load Requirement descriptions and split them into chunks for embedding\n\n---\n\n## Why a Manufacturing Traceability Graph?\n\nIn automotive manufacturing, traceability is critical. Engineers need to trace from a product all the way down to individual test results and defects. A knowledge graph naturally represents these relationships:\n\n```\n(Product) -[:PRODUCT_HAS_DOMAIN]-> (TechnologyDomain) -[:DOMAIN_HAS_COMPONENT]-> (Component)\n    (Component) -[:COMPONENT_HAS_REQ]-> (Requirement) -[:HAS_CHUNK]-> (Chunk) -[:NEXT_CHUNK]-> (Chunk)\n```\n\nThis structure enables:\n- **Impact analysis**: When a change is proposed, trace which requirements, components, and tests are affected\n- **Traceability**: Follow the chain from product definition to test results and defects\n- **Semantic search**: Find requirements by meaning using vector embeddings on chunk text\n\n---\n\n## Text Splitting with neo4j-graphrag-python\n\nRequirement descriptions contain detailed engineering specifications. We split them into smaller **chunks** for embedding because:\n\n1. **Retrieval precision** - A 500-character chunk about \"thermal management\" is more relevant to a query about cooling than an entire multi-paragraph requirement\n2. **Embedding quality** - Embedding models produce better representations for focused text segments\n3. **Context windows** - LLMs can only process a certain amount of text at once\n\nWe'll use `FixedSizeSplitter` from the [neo4j-graphrag-python](https://neo4j.com/docs/neo4j-graphrag-python/current/) library:\n\n- `chunk_size`: Maximum characters per chunk (e.g., 500 or 1000)\n- `chunk_overlap`: Characters shared between consecutive chunks for context continuity\n- `approximate=True` (default): Avoids splitting words mid-token"
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "First, install the required packages. This only needs to be run once per session."
   ]
  },
  {
   "cell_type": "code",
   "id": "install-deps",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install neo4j-graphrag with Bedrock support\n",
    "%pip install \"neo4j-graphrag[bedrock] @ git+https://github.com/neo4j-partners/neo4j-graphrag-python.git@bedrock-embeddings\" python-dotenv pydantic-settings nest-asyncio -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import required modules and configure the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "from data_utils import Neo4jConnection, CSVLoader, DataLoader, split_text"
  },
  {
   "cell_type": "markdown",
   "id": "sample-data-header",
   "metadata": {},
   "source": "## Load Manufacturing Data from CSVs\n\nWe'll load structured manufacturing data from CSV files in the `TransformedData/` directory. The CSVs contain products, technology domains, components, and their relationships.\n\nWe'll also load requirement description text from `manufacturing_data.txt` for chunking and embedding demonstrations."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sample-data",
   "metadata": {},
   "outputs": [],
   "source": "# Load CSV data from TransformedData directory\ncsv_loader = CSVLoader(\"../TransformedData\")\n\nproducts = csv_loader.load_csv(\"products.csv\")\ntech_domains = csv_loader.load_csv(\"technology_domains.csv\")\ncomponents = csv_loader.load_csv(\"components.csv\")\nproduct_domains = csv_loader.load_csv(\"product_technology_domains.csv\")\ndomain_components = csv_loader.load_csv(\"technology_domains_components.csv\")\n\nprint(f\"Products: {len(products)}\")\nfor p in products:\n    print(f\"  {p['product_id']}: {p['Product Name']} - {p['Description']}\")\n\nprint(f\"\\nTechnology Domains: {len(tech_domains)}\")\nfor td in tech_domains:\n    print(f\"  {td['technology_domain_id']}: {td['Technology Domain']}\")\n\nprint(f\"\\nComponents: {len(components)}\")\nfor c in components:\n    print(f\"  {c['component_id']}: {c['Component']} - {c['Component Description']}\")\n\n# Also load requirement text for chunking demo\nloader = DataLoader(\"manufacturing_data.txt\")\nSAMPLE_TEXT = loader.text\nmetadata = loader.get_metadata()\nprint(f\"\\nRequirement text: {metadata['size']} characters\")"
  },
  {
   "cell_type": "markdown",
   "id": "connect-header",
   "metadata": {},
   "source": [
    "## Connect to Neo4j\n",
    "\n",
    "Create a connection to your Neo4j database using the `Neo4jConnection` utility class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "connect",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j = Neo4jConnection().verify()\n",
    "driver = neo4j.driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-header",
   "metadata": {},
   "source": "## Clear Existing Data (Optional)\n\nFor a clean start, remove any existing nodes from previous runs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clear-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "neo4j.clear_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create-doc-header",
   "metadata": {},
   "source": "## Create Product, TechnologyDomain, and Component Nodes\n\nFirst, create the top-level entities from the CSV data. These form the structural backbone of the manufacturing traceability graph.\n\n- **Product**: The vehicle under development (R2D2)\n- **TechnologyDomain**: Major technology areas (Electric Powertrain, Chassis, Body, Infotainment)\n- **Component**: Hardware components (HVB_3900 battery, PDU_1500 power distribution unit, etc.)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-document",
   "metadata": {},
   "outputs": [],
   "source": "def create_products(driver, products):\n    \"\"\"Create Product nodes from CSV data.\"\"\"\n    with driver.session() as session:\n        for p in products:\n            session.run(\"\"\"\n                CREATE (p:Product {product_id: $id, name: $name, description: $desc})\n            \"\"\", id=p[\"product_id\"], name=p[\"Product Name\"], desc=p[\"Description\"])\n    print(f\"Created {len(products)} Product nodes\")\n\ndef create_technology_domains(driver, domains):\n    \"\"\"Create TechnologyDomain nodes from CSV data.\"\"\"\n    with driver.session() as session:\n        for td in domains:\n            session.run(\"\"\"\n                CREATE (t:TechnologyDomain {technology_domain_id: $id, name: $name})\n            \"\"\", id=td[\"technology_domain_id\"], name=td[\"Technology Domain\"])\n    print(f\"Created {len(domains)} TechnologyDomain nodes\")\n\ndef create_components(driver, components):\n    \"\"\"Create Component nodes from CSV data.\"\"\"\n    with driver.session() as session:\n        for c in components:\n            session.run(\"\"\"\n                CREATE (c:Component {component_id: $id, name: $name, description: $desc})\n            \"\"\", id=c[\"component_id\"], name=c[\"Component\"], desc=c[\"Component Description\"])\n    print(f\"Created {len(components)} Component nodes\")\n\ncreate_products(driver, products)\ncreate_technology_domains(driver, tech_domains)\ncreate_components(driver, components)"
  },
  {
   "cell_type": "markdown",
   "id": "chunk-header",
   "metadata": {},
   "source": "## Create Relationships\n\nNow create the relationships that form the traceability chain. We use the junction table CSVs to connect:\n- **PRODUCT_HAS_DOMAIN**: Product → TechnologyDomain\n- **DOMAIN_HAS_COMPONENT**: TechnologyDomain → Component\n\nThese relationships are created by matching nodes on their IDs from the junction CSVs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-text",
   "metadata": {},
   "outputs": [],
   "source": "def create_product_domain_rels(driver, product_domains):\n    \"\"\"Create PRODUCT_HAS_DOMAIN relationships.\"\"\"\n    with driver.session() as session:\n        for row in product_domains:\n            session.run(\"\"\"\n                MATCH (p:Product {product_id: $pid})\n                MATCH (t:TechnologyDomain {technology_domain_id: $tid})\n                CREATE (p)-[:PRODUCT_HAS_DOMAIN]->(t)\n            \"\"\", pid=row[\"product_id\"], tid=row[\"technology_domain_id\"])\n    print(f\"Created {len(product_domains)} PRODUCT_HAS_DOMAIN relationships\")\n\ndef create_domain_component_rels(driver, domain_components):\n    \"\"\"Create DOMAIN_HAS_COMPONENT relationships.\"\"\"\n    with driver.session() as session:\n        for row in domain_components:\n            session.run(\"\"\"\n                MATCH (t:TechnologyDomain {technology_domain_id: $tid})\n                MATCH (c:Component {component_id: $cid})\n                CREATE (t)-[:DOMAIN_HAS_COMPONENT]->(c)\n            \"\"\", tid=row[\"technology_domain_id\"], cid=row[\"component_id\"])\n    print(f\"Created {len(domain_components)} DOMAIN_HAS_COMPONENT relationships\")\n\ncreate_product_domain_rels(driver, product_domains)\ncreate_domain_component_rels(driver, domain_components)"
  },
  {
   "cell_type": "markdown",
   "id": "create-chunks-header",
   "metadata": {},
   "source": "## Split Requirement Text into Chunks\n\nNow we demonstrate text chunking on the requirement descriptions. This is how we prepare text-rich content for vector embedding and semantic search.\n\nWe load a consolidated requirement description text file and split it into chunks using `FixedSizeSplitter`. Each chunk becomes a node linked to a parent Requirement node with `HAS_CHUNK` and `NEXT_CHUNK` relationships."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-chunks",
   "metadata": {},
   "outputs": [],
   "source": "# Split requirement text into chunks\nchunks = split_text(SAMPLE_TEXT, chunk_size=500, chunk_overlap=50)\n\nprint(f\"Split into {len(chunks)} chunks:\\n\")\nfor i, chunk in enumerate(chunks):\n    print(f\"Chunk {i}: {len(chunk)} chars\")\n    print(f\"  {chunk[:100]}...\\n\")"
  },
  {
   "cell_type": "markdown",
   "id": "link-chunks-header",
   "metadata": {},
   "source": "## Create Requirement and Chunk Nodes\n\nCreate a Requirement node to represent the source requirement, then create Chunk nodes for each piece of text. Link chunks to the requirement with `HAS_CHUNK` and to each other with `NEXT_CHUNK`.\n\nThe `NEXT_CHUNK` relationships preserve the original text order, enabling **context expansion** — when you find a relevant chunk via vector search, you can retrieve adjacent chunks for additional context."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "link-chunks",
   "metadata": {},
   "outputs": [],
   "source": "def create_requirement_with_chunks(driver, requirement_name, chunks):\n    \"\"\"Create a Requirement node and linked Chunk nodes.\"\"\"\n    with driver.session() as session:\n        # Create Requirement node\n        result = session.run(\"\"\"\n            CREATE (r:Requirement {requirement_id: '1_1', name: $name,\n                description: 'Battery Cell and Module Design'})\n            RETURN elementId(r) as req_id\n        \"\"\", name=requirement_name)\n        req_id = result.single()[\"req_id\"]\n        print(f\"Created Requirement: {requirement_name}\")\n\n        # Link Requirement to Component\n        session.run(\"\"\"\n            MATCH (r:Requirement) WHERE elementId(r) = $req_id\n            MATCH (c:Component {name: 'HVB_3900'})\n            CREATE (c)-[:COMPONENT_HAS_REQ]->(r)\n        \"\"\", req_id=req_id)\n        print(\"Created COMPONENT_HAS_REQ relationship\")\n\n        # Create Chunk nodes with HAS_CHUNK relationships\n        chunk_ids = []\n        for index, text in enumerate(chunks):\n            result = session.run(\"\"\"\n                MATCH (r:Requirement) WHERE elementId(r) = $req_id\n                CREATE (c:Chunk {text: $text, index: $index})\n                CREATE (r)-[:HAS_CHUNK]->(c)\n                RETURN elementId(c) as chunk_id\n            \"\"\", req_id=req_id, text=text, index=index)\n            chunk_ids.append(result.single()[\"chunk_id\"])\n            print(f\"Created Chunk {index}\")\n\n        # Create NEXT_CHUNK relationships\n        for i in range(len(chunk_ids) - 1):\n            session.run(\"\"\"\n                MATCH (c1:Chunk) WHERE elementId(c1) = $id1\n                MATCH (c2:Chunk) WHERE elementId(c2) = $id2\n                CREATE (c1)-[:NEXT_CHUNK]->(c2)\n            \"\"\", id1=chunk_ids[i], id2=chunk_ids[i+1])\n        print(f\"Created {len(chunk_ids) - 1} NEXT_CHUNK relationships\")\n\ncreate_requirement_with_chunks(driver, \"Battery Cell and Module Design\", chunks)"
  },
  {
   "cell_type": "markdown",
   "id": "verify-header",
   "metadata": {},
   "source": [
    "## Verify the Graph Structure\n",
    "\n",
    "Query the graph to see what we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify",
   "metadata": {},
   "outputs": [],
   "source": "def show_graph_structure(driver):\n    \"\"\"Display the manufacturing graph structure.\"\"\"\n    with driver.session() as session:\n        # Count nodes by label\n        result = session.run(\"\"\"\n            CALL db.labels() YIELD label\n            CALL (label) {\n                MATCH (n) WHERE label IN labels(n)\n                RETURN count(n) as count\n            }\n            RETURN label, count\n            ORDER BY count DESC\n        \"\"\")\n        print(\"=== Node Counts ===\")\n        for record in result:\n            print(f\"  {record['label']}: {record['count']}\")\n\n        # Show traceability chain\n        print(\"\\n=== Traceability Chain ===\")\n        result = session.run(\"\"\"\n            MATCH (p:Product)-[:PRODUCT_HAS_DOMAIN]->(td:TechnologyDomain)\n                    -[:DOMAIN_HAS_COMPONENT]->(c:Component)\n            RETURN p.name as product, td.name as domain, c.name as component\n            ORDER BY td.name, c.name\n        \"\"\")\n        for record in result:\n            print(f\"  {record['product']} -> {record['domain']} -> {record['component']}\")\n\n        # Show chunk chain\n        print(\"\\n=== Requirement Chunks ===\")\n        result = session.run(\"\"\"\n            MATCH (r:Requirement)-[:HAS_CHUNK]->(c:Chunk)\n            RETURN r.name as requirement, count(c) as chunks\n        \"\"\")\n        for record in result:\n            print(f\"  {record['requirement']}: {record['chunks']} chunks\")\n\nshow_graph_structure(driver)"
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": "## Summary\n\nIn this notebook, you learned the foundational graph structure for manufacturing GraphRAG applications:\n\n1. **Structured data loading** - Products, TechnologyDomains, and Components loaded from CSV files into Neo4j as nodes.\n\n2. **Traceability relationships** - PRODUCT_HAS_DOMAIN and DOMAIN_HAS_COMPONENT relationships form the top of the traceability chain, enabling queries like \"what components belong to the Electric Powertrain domain?\"\n\n3. **Requirement chunking** - Requirement description text split into Chunk nodes linked by HAS_CHUNK and NEXT_CHUNK relationships, preparing the text for vector embedding.\n\n4. **Graph advantages** - The graph structure lets us combine structured manufacturing data (products, components) with unstructured text (requirement descriptions) in a single queryable model.\n\nIn the next notebook, you'll learn to add **embeddings** to these chunks, enabling semantic similarity search over requirement descriptions.\n\n---\n\n**Next:** [Embeddings and Vector Search](02_embeddings.ipynb)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "neo4j.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}