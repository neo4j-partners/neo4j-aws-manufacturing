{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-01",
   "metadata": {},
   "source": "# Minimal LangGraph Agent for SageMaker Studio\n\nThis notebook demonstrates how to build a simple ReAct-style agent using **LangGraph** and **AWS Bedrock**. \n\nYou'll learn how to:\n- Configure and connect to Claude models via Bedrock\n- Define custom tools that the agent can use\n- Build a graph-based agent that reasons and acts\n- Test the agent with various queries\n\n**Prerequisites:** Ensure your model is configured in `../CONFIG.txt` before running."
  },
  {
   "cell_type": "code",
   "id": "asqvbyrqcs",
   "source": "# Load configuration from CONFIG.txt\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv(\"../CONFIG.txt\")\n\nMODEL_ID = os.getenv(\"MODEL_ID\")\nREGION = os.getenv(\"REGION\", \"us-west-2\")\n\n# Derive BASE_MODEL_ID for Claude inference profiles\n# us.anthropic.claude-* -> anthropic.claude-*\nif MODEL_ID and MODEL_ID.startswith(\"us.anthropic.\"):\n    BASE_MODEL_ID = MODEL_ID.replace(\"us.anthropic.\", \"anthropic.\")\nelse:\n    BASE_MODEL_ID = None\n\nprint(f\"Model:  {MODEL_ID}\")\nif BASE_MODEL_ID:\n    print(f\"Base:   {BASE_MODEL_ID}\")\nprint(f\"Region: {REGION}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import importlib.metadata\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-core\",\n",
    "    \"langgraph\",\n",
    "    \"langchain-aws\",\n",
    "    \"langchain-mcp-adapters\",\n",
    "    \"mcp\",\n",
    "    \"httpx\",\n",
    "    \"boto3\",\n",
    "]\n",
    "\n",
    "print(\"Pre-installed packages:\")\n",
    "print(\"-\" * 50)\n",
    "for pkg in packages:\n",
    "    try:\n",
    "        version = importlib.metadata.version(pkg)\n",
    "        print(f\"{pkg:30} {version}\")\n",
    "    except importlib.metadata.PackageNotFoundError:\n",
    "        print(f\"{pkg:30} NOT INSTALLED\")"
   ],
   "id": "9e4c3dc65590a95b"
  },
  {
   "cell_type": "code",
   "id": "dja9b93hwjo",
   "source": "# Install missing packages\n%pip install langgraph>=1.0.6 -q",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "imports-header",
   "metadata": {},
   "source": "## 2. Imports\n\nImport the required libraries for building our agent:\n- **LangChain AWS**: Provides the `ChatBedrockConverse` class for Bedrock integration\n- **LangGraph**: Framework for building stateful, graph-based agents\n- **LangChain Core**: Message types and tool decorators"
  },
  {
   "cell_type": "code",
   "id": "imports",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "print(\"Imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tools-header",
   "metadata": {},
   "source": "## 3. Define Tools\n\nTools are functions that the agent can call to perform actions or retrieve information. We use the `@tool` decorator to register them with LangChain.\n\nHere we define two simple tools:\n- **get_current_time**: Returns the current date and time\n- **add_numbers**: Adds two integers together\n\nThe agent will automatically decide when to use these tools based on the user's question."
  },
  {
   "cell_type": "code",
   "id": "tools",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "@tool\n",
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "tools = [get_current_time, add_numbers]\n",
    "print(f\"Defined {len(tools)} tools: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "llm-header",
   "metadata": {},
   "source": "## 4. Initialize the LLM\n\nCreate a connection to Claude via AWS Bedrock using `ChatBedrockConverse`. This class uses the Bedrock Converse API, which provides a unified interface for all supported models.\n\nKey configuration:\n- **model**: The model ID from CONFIG.txt (e.g., `us.anthropic.claude-3-sonnet-20240229-v1:0`)\n- **region_name**: AWS region where Bedrock is available\n- **temperature**: Controls randomness (0 = deterministic, 1 = creative)\n\nAfter initialization, we bind our tools to the LLM so it knows what actions are available."
  },
  {
   "cell_type": "code",
   "id": "llm-setup",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": "# Build LLM config - add base_model_id for Claude inference profiles\nllm_kwargs = {\n    \"model\": MODEL_ID,\n    \"region_name\": REGION,\n    \"temperature\": 0,\n}\n\nif BASE_MODEL_ID:\n    llm_kwargs[\"base_model_id\"] = BASE_MODEL_ID\n\nllm = ChatBedrockConverse(**llm_kwargs)\n\n# Bind tools to the LLM\nllm_with_tools = llm.bind_tools(tools)\n\nprint(f\"LLM initialized with {MODEL_ID}!\")"
  },
  {
   "cell_type": "markdown",
   "id": "graph-header",
   "metadata": {},
   "source": "## 5. Build the LangGraph Agent\n\nLangGraph allows us to build agents as **directed graphs** where:\n- **Nodes** are functions that process state (e.g., call the LLM, execute tools)\n- **Edges** define the flow between nodes\n- **Conditional edges** route based on the current state\n\nOur agent follows the **ReAct pattern** (Reason + Act):\n1. The `agent` node calls the LLM to decide what to do\n2. If the LLM requests tool calls, route to the `tools` node\n3. The `tools` node executes the requested tools\n4. Return to `agent` to process results and continue reasoning\n5. When no more tools are needed, end the conversation"
  },
  {
   "cell_type": "code",
   "id": "graph-build",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def should_continue(state: MessagesState) -> Literal[\"tools\", \"__end__\"]:\n",
    "    \"\"\"Determine whether to continue to tools or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Call the LLM.\"\"\"\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# Build the graph\n",
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# Add nodes\n",
    "graph.add_node(\"agent\", call_model)\n",
    "graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges\n",
    "graph.add_edge(START, \"agent\")\n",
    "graph.add_conditional_edges(\"agent\", should_continue)\n",
    "graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile\n",
    "agent = graph.compile()\n",
    "\n",
    "print(\"Agent graph compiled successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualize-header",
   "metadata": {},
   "source": "## 6. Visualize the Graph (Optional)\n\nLangGraph can render the agent's graph structure as a diagram. This helps visualize how messages flow between nodes and understand the agent's decision-making process.\n\n**Note:** Requires `graphviz` to be installed. If not available, a text representation is shown instead."
  },
  {
   "cell_type": "code",
   "id": "visualize",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the graph structure (requires graphviz)\n",
    "try:\n",
    "    from IPython.display import Image, display\n",
    "    display(Image(agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Graph visualization not available: {e}\")\n",
    "    print(\"\\nGraph structure:\")\n",
    "    print(\"  START -> agent -> (tools -> agent) | END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "run-header",
   "metadata": {},
   "source": "## 7. Run the Agent\n\nNow let's test the agent! The `run_agent` function:\n1. Takes a question as input\n2. Wraps it with a system message defining the assistant's behavior\n3. Invokes the agent graph\n4. Returns the final response\n\nThe agent will automatically use tools when needed to answer the question."
  },
  {
   "cell_type": "code",
   "id": "run-agent",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_agent(question: str):\n",
    "    \"\"\"Run the agent with a question and display the response.\"\"\"\n",
    "    print(f\"Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=\"You are a helpful assistant. Use tools when needed.\"),\n",
    "            HumanMessage(content=question),\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    final_message = result[\"messages\"][-1]\n",
    "    print(f\"\\nResponse:\\n{final_message.content}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-time",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Get current time\n",
    "result = run_agent(\"What is the current time?\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-math",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Math calculation\n",
    "result = run_agent(\"What is 42 + 17?\")"
   ]
  },
  {
   "cell_type": "code",
   "id": "test-both",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Test: Multiple tools\n",
    "result = run_agent(\"What time is it and what is 100 + 200?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1pdivtjrsl",
   "source": "## 9. Query with Sample Manufacturing Data\n\nThis section demonstrates how to provide context to the agent. We load sample manufacturing data and ask the agent questions about it.\n\nThis pattern is useful for:\n- **RAG (Retrieval-Augmented Generation)**: Injecting retrieved documents into prompts\n- **In-context learning**: Providing examples or data for the agent to reference\n- **Domain-specific Q&A**: Answering questions based on proprietary information",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "o1qri9pwatb",
   "source": "# Load sample manufacturing data\nfrom load_sample_data import load_manufacturing_data, print_info\n\nmanufacturing_text = load_manufacturing_data()\nprint_info(manufacturing_text)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "0jv7ule45vm5",
   "source": "# Ask the agent questions about the manufacturing data\ndef ask_about_data(question: str, context: str):\n    \"\"\"Ask the agent a question with context.\"\"\"\n    prompt = f\"\"\"Based on this manufacturing information:\n\n{context}\n\nQuestion: {question}\"\"\"\n    return run_agent(prompt)\n\n# Sample questions\nask_about_data(\"What components are in the Electric Powertrain domain?\", manufacturing_text)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7u7fqe1mf8w",
   "source": "# Another sample question\nask_about_data(\"What defects have been found and what are their severities?\", manufacturing_text)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}